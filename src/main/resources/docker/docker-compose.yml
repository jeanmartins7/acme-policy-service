services:

  dynamodb-local:
    command: "-jar DynamoDBLocal.jar -sharedDb -dbPath ./data"
    image: "amazon/dynamodb-local:latest"
    user: root
    ports:
      - "8000:8000"
    volumes:
      - "./docker-data:/home/dynamodblocal/data:rw"
    working_dir: /home/dynamodblocal
    healthcheck:
      test: [ "CMD-SHELL", '[ "$(curl -s -o /dev/null -I -w ''%{http_code}'' http://localhost:8000)" == "400" ]' ]
      interval: 10s
      timeout: 10s
      retries: 10

  dynamodb-initializer:
    depends_on:
      dynamodb-local:
        condition: service_healthy
    build:
      context: .
      dockerfile: dynamodb-initializer.Dockerfile
    volumes:
      - "./schemas:/tmp/dynamo:rw"
    environment:
      AWS_ACCESS_KEY_ID: 'FAKEID'
      AWS_SECRET_ACCESS_KEY: 'FAKEKEY'
      AWS_REGION: 'us-east-1'
    entrypoint:
      - sh
    command:
      - -c
      - |
        set -x
        echo "Waiting for dynamodb-local to be ready..."
        while ! nc -z dynamodb-local 8000; do
          sleep 1;
        done;
        echo "dynamodb-local is ready. Starting table creation/check."

        for f in /tmp/dynamo/*.json; do
          TABLE_NAME=$$(jq -r '.TableName' "$$f");

          if [ -z "$$TABLE_NAME" ]; then
            echo "Error: Could not extract TableName from $$f. Skipping this file.";
            continue;
          fi

          if aws dynamodb describe-table --table-name "$$TABLE_NAME" --endpoint-url "http://dynamodb-local:8000" 2>/dev/null; then
            echo "Table $$TABLE_NAME already exists. Skipping creation.";
          else
            echo "Creating table $$TABLE_NAME...";
            aws dynamodb create-table --endpoint-url "http://dynamodb-local:8000" --cli-input-json file://"$${f}";
            echo "Finished creating table $$TABLE_NAME."
          fi;
        done
        echo "DynamoDB initialization complete."

  kafka-init:
    image: apache/kafka:latest
    container_name: kafka-init
    command: ["/bin/bash", "-c", "
      /opt/kafka/bin/kafka-storage.sh random-uuid > /tmp/cluster_id.txt;
      CLUSTER_ID=$$(cat /tmp/cluster_id.txt);
      echo 'Generated CLUSTER_ID: '$$CLUSTER_ID;
      /opt/kafka/bin/kafka-storage.sh format -t $$CLUSTER_ID -c /opt/kafka/config/kraft/server.properties;
      sleep infinity;
    "]
    volumes:
      - "kafka_data:/var/lib/kafka/data"

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost 2181 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 15s
    ports:
        - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      CONFLUENT_METRICS_ENABLE: 'true'
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.3
    container_name: schema-registry
    hostname: schema-registry
    ports:
      - "8081:8081"
    depends_on:
      kafka:
        condition: service_healthy
      zookeeper:
        condition: service_healthy
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka:9092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/subjects || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s


  control-center:
    image: confluentinc/cp-enterprise-control-center:7.5.3
    hostname: control-center
    container_name: control-center
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_INTERNAL_TOPICS_REPLICATION: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS: 1
      CONTROL_CENTER_STREAMS_CACHE_MAX_BYTES_BUFFERING: 104857600
      PORT: 9021
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_REPLICATION: 1
      CONTROL_CENTER_MODE_ENABLE: 'all'
      CONTROL_CENTER_CONSUMERS_VIEW_ENABLE: 'true'
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9021/health || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 15
      start_period: 90s

  wiremock:
    image: wiremock/wiremock:3.5.4
    container_name: wiremock
    ports:
      - "8080:8080"
    volumes:
      - "./wiremock:/home/wiremock:rw"
    command: --root-dir /home/wiremock --verbose
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/__admin/mappings || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5

  jaeger:
    image: jaegertracing/all-in-one:1.57
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411
    ports:
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:16686/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s

  collector:
    image: otel/opentelemetry-collector-contrib:0.104.0
    container_name: collector
    restart: unless-stopped
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - "./otel/otel-collector-config.yaml:/etc/otel-collector-config.yaml"
    ports:
      - "13133:13133"
      - "4317:4317"
      - "4318:4318"
      - "8888:8888"
      - "9464:9464"
    depends_on:
      - jaeger
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:4318/ || exit 1"]
      interval: 5s
      retries: 10
      start_period: 10s
      timeout: 3s

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - "./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml"
      - "prometheus_data:/prometheus"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=false'
      - '--web.console.templates=false'
      - '--web.enable-remote-write-receiver'
    depends_on:
      - collector
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:9090/-/healthy || exit 1" ]
      interval: 5s
      retries: 10
      start_period: 10s
      timeout: 3s

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - "grafana_data:/var/lib/grafana "
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus

volumes:
  dynamodb_data:
  prometheus_data:
  grafana_data:
  kafka_data:
    driver: local

networks:
  default:
    driver: bridge