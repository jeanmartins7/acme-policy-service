services:

  dynamodb-local:
    command: "-jar DynamoDBLocal.jar -sharedDb -dbPath ./data"
    image: "amazon/dynamodb-local:latest"
    user: root
    ports:
      - "8000:8000"
    volumes:
      - "./docker-data:/home/dynamodblocal/data:rw"
    working_dir: /home/dynamodblocal
    healthcheck:
      test: [ "CMD-SHELL", '[ "$(curl -s -o /dev/null -I -w ''%{http_code}'' http://localhost:8000)" == "400" ]' ]
      interval: 10s
      timeout: 10s
      retries: 10

  dynamodb-initializer:
    depends_on:
      dynamodb-local:
        condition: service_healthy
    build:
      context: .
      dockerfile: dynamodb-initializer.Dockerfile
    volumes:
      - "./schemas:/tmp/dynamo:rw"
    environment:
      AWS_ACCESS_KEY_ID: 'FAKEID'
      AWS_SECRET_ACCESS_KEY: 'FAKEKEY'
      AWS_REGION: 'us-east-1'
    entrypoint:
      - sh
    command:
      - -c
      - |
        set -x
        echo "Waiting for dynamodb-local to be ready..."
        while ! nc -z dynamodb-local 8000; do
          sleep 1;
        done;
        echo "dynamodb-local is ready. Starting table creation/check."

        for f in /tmp/dynamo/*.json; do
          TABLE_NAME=$$(jq -r '.TableName' "$$f");

          if [ -z "$$TABLE_NAME" ]; then
            echo "Error: Could not extract TableName from $$f. Skipping this file.";
            continue;
          fi

          if aws dynamodb describe-table --table-name "$$TABLE_NAME" --endpoint-url "http://dynamodb-local:8000" 2>/dev/null; then
            echo "Table $$TABLE_NAME already exists. Skipping creation.";
          else
            echo "Creating table $$TABLE_NAME...";
            aws dynamodb create-table --endpoint-url "http://dynamodb-local:8000" --cli-input-json file://"$${f}";
            echo "Finished creating table $$TABLE_NAME."
          fi;
        done
        echo "DynamoDB initialization complete."

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      CONFLUENT_METRICS_ENABLE: 'true'
    extra_hosts:
      - "host.docker.internal:172.17.0.1"

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    container_name: schema-registry
    hostname: schema-registry
    ports:
      - "8081:8081"
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka:9092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

  control-center:
    image: confluentinc/cp-enterprise-control-center:latest
    hostname: control-center
    container_name: control-center
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_REPLICATION: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_INTERNAL_TOPICS_REPLICATION: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS: 1
      CONTROL_CENTER_MODE_ENABLE: 'all'
      CONTROL_CENTER_CONSUMERS_VIEW_ENABLE: 'true'
      CONTROL_CENTER_STREAMS_CACHE_MAX_BYTES_BUFFERING: 104857600
      PORT: 9021
    command:
      - bash
      - -c
      - |
        echo "Waiting two minutes for Kafka brokers to start and
               necessary topics to be available"
        sleep 60
        /etc/confluent/docker/run
    extra_hosts:
      - "host.docker.internal:172.17.0.1"

  wiremock:
    image: wiremock/wiremock:3.5.4
    container_name: wiremock
    ports:
      - "8080:8080"
    volumes:
      - "./wiremock:/home/wiremock:rw"
    command: --root-dir /home/wiremock --verbose
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/__admin/mappings || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5

  jaeger:
    image: jaegertracing/all-in-one:1.57
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411
    ports:
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"

  collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: collector
    restart: unless-stopped
    command: ["--config=/etc/otlp-collector-config.yaml"]
    volumes:
      - ./otlp/otlp-collector-config.yaml:/etc/otlp-collector-config.yaml
      - "13133:13133"
      - "4317:4317"
      - "4318:4318"
      - "8888:8888"
    depends_on:
      - jaeger
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8888/metrics || exit 1"]
      interval: 5s
      retries: 10
      start_period: 10s
      timeout: 3s

  #order-microservice:
    #image: order-microservice:latest
    #container_name: order-microservice
    #ports:
      #- "8090:8090"
    #depends_on:
      #collector:
        #condition: service_healthy
    #environment:
      #SPRING_PROFILES_ACTIVE: local
    #networks:
      #- default



volumes:
  kafka-data:
    driver: local

networks:
  default:
    driver: bridge